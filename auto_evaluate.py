#!/usr/bin/env python3
"""
OpenAIX æ¯å°æ—¶è‡ªåŠ¨è¯„æµ‹è„šæœ¬ v2.0
- æ¯å°æ—¶è¯„æµ‹5ä¸ªç½‘ç«™
- å…¨å±€å»é‡ï¼Œä¸é‡å¤è¯„æµ‹
- ä¼˜åŒ–ç›®å½•ç»“æ„ï¼šæŒ‰æ—¥æœŸåˆ†ç›®å½•
- æ›´æ–° README å¹¶æ¨é€åˆ° GitHub
"""

import os
import sys
import json
import random
import subprocess
from datetime import datetime
from pathlib import Path

# é…ç½®
PROJECT_DIR = Path("/home/wesley/.openclaw/workspace/openaix-core")
DATA_DIR = PROJECT_DIR / "data" / "evaluations"
URLS_FILE = PROJECT_DIR / "websites.txt"
BENCHMARK_SCRIPT = PROJECT_DIR / "benchmark.py"
VENV_PYTHON = PROJECT_DIR / "venv" / "bin" / "python3"
EVALUATED_LOG = DATA_DIR / "evaluated_sites.json"
BATCH_SIZE = 5  # æ¯å°æ—¶è¯„æµ‹æ•°é‡

# ç¡®ä¿ç›®å½•å­˜åœ¨
DATA_DIR.mkdir(parents=True, exist_ok=True)

# é»˜è®¤ç½‘ç«™åˆ—è¡¨
DEFAULT_WEBSITES = [
    "https://openai.com",
    "https://anthropic.com",
    "https://claude.ai",
    "https://gemini.google.com",
    "https://docs.python.org",
    "https://github.com",
    "https://stackoverflow.com",
    "https://medium.com",
    "https://apple.com",
    "https://google.com",
    "https://microsoft.com",
    "https://amazon.com",
    "https://shopify.com",
    "https://notion.so",
    "https://figma.com",
    "https://vercel.com",
    "https://nextjs.org",
    "https://react.dev",
    "https://vuejs.org",
    "https://tailwindcss.com",
    "https://stripe.com",
    "https://twilio.com",
    "https://developer.mozilla.org",
    "https://docs.npmjs.com",
    "https://angular.io",
    "https://docs.astro.build",
    "https://netlify.com",
    "https://cloudflare.com",
    "https://aws.amazon.com",
    "https://linear.app",
    "https://substack.com",
    "https://dev.to",
    "https://meta.com",
    "https://twitter.com",
    "https://nodejs.org",
    "https://redis.io",
    "https://postgresql.org",
    "https://mongodb.com",
]


def load_websites():
    """åŠ è½½ç½‘ç«™åˆ—è¡¨"""
    if URLS_FILE.exists():
        with open(URLS_FILE, 'r') as f:
            return [line.strip() for line in f if line.strip() and not line.startswith('#')]
    return DEFAULT_WEBSITES


def get_evaluated_sites():
    """è·å–æ‰€æœ‰å·²è¯„æµ‹è¿‡çš„ç½‘ç«™ï¼ˆå…¨å±€å»é‡ï¼‰"""
    evaluated = set()
    
    # ä»æ—¥å¿—æ–‡ä»¶è¯»å–
    if EVALUATED_LOG.exists():
        try:
            with open(EVALUATED_LOG, 'r') as f:
                data = json.load(f)
                evaluated.update(data.get('sites', []))
        except:
            pass
    
    # ä»ç°æœ‰JSONæ–‡ä»¶æ‰«æï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
    for json_file in DATA_DIR.rglob('*.json'):
        if json_file.name == 'evaluated_sites.json':
            continue
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                if data.get('url'):
                    evaluated.add(data['url'])
        except:
            pass
    
    return evaluated


def save_evaluated_sites(sites):
    """ä¿å­˜å·²è¯„æµ‹ç½‘ç«™åˆ—è¡¨"""
    data = {
        'sites': list(sites),
        'last_updated': datetime.now().isoformat(),
        'total_count': len(sites)
    }
    with open(EVALUATED_LOG, 'w') as f:
        json.dump(data, f, indent=2)


def select_websites(batch_size=BATCH_SIZE):
    """é€‰æ‹©ä¸€æ‰¹æœªè¯„æµ‹çš„ç½‘ç«™"""
    websites = load_websites()
    evaluated = get_evaluated_sites()
    
    # è¿‡æ»¤æœªè¯„æµ‹çš„
    candidates = [url for url in websites if url not in evaluated]
    
    if len(candidates) < batch_size:
        print(f"âš ï¸ å‰©ä½™æœªè¯„æµ‹ç½‘ç«™ä»… {len(candidates)} ä¸ªï¼Œä¸è¶³ {batch_size} ä¸ª")
        print("   å°†ä»å…¨éƒ¨ç½‘ç«™ä¸­éšæœºé€‰æ‹©ï¼ˆä¼šé‡å¤è¯„æµ‹ï¼‰")
        candidates = websites
    
    # éšæœºé€‰æ‹© batch_size ä¸ª
    selected = random.sample(candidates, min(batch_size, len(candidates)))
    return selected


def evaluate_website(url, output_dir):
    """è¯„æµ‹å•ä¸ªç½‘ç«™"""
    timestamp = datetime.now().strftime('%H%M%S')
    domain = url.replace('https://', '').replace('http://', '').replace('/', '_')
    output_file = output_dir / f"{timestamp}_{domain}.json"
    report_file = output_dir / f"{timestamp}_{domain}.md"
    
    print(f"\nğŸ” è¯„æµ‹: {url}")
    
    cmd = [
        str(VENV_PYTHON),
        str(BENCHMARK_SCRIPT),
        url,
        "--output", str(report_file),
        "--json",
        "--timeout", "15"
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            json_file = str(report_file).replace('.md', '.json')
            if os.path.exists(json_file):
                with open(json_file, 'r') as f:
                    data = json.load(f)
                
                evaluation = {
                    "url": url,
                    "timestamp": datetime.now().isoformat(),
                    "result": data[0] if data else None
                }
                
                with open(output_file, 'w') as f:
                    json.dump(evaluation, f, indent=2)
                
                if evaluation["result"] and evaluation["result"].get("success"):
                    score = evaluation["result"]["result"]["score"]
                    grade = evaluation["result"]["result"]["grade"]
                    print(f"   âœ… {score}/100 ({grade})")
                    return evaluation
        
        print(f"   âŒ å¤±è´¥")
        return None
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {e}")
        return None


def update_readme(evaluations):
    """æ›´æ–° README å±•ç¤ºæœ€æ–°è¯„æµ‹ç»“æœ"""
    # è¯»å–å†å²æ‰€æœ‰è¯„æµ‹
    all_evals = []
    for json_file in DATA_DIR.rglob('*.json'):
        if json_file.name in ['evaluated_sites.json']:
            continue
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                if data.get("result") and data["result"].get("success"):
                    all_evals.append(data)
        except:
            pass
    
    # æŒ‰URLå»é‡ï¼Œä¿ç•™æœ€æ–°çš„
    seen_urls = {}
    for eval in sorted(all_evals, key=lambda x: x.get('timestamp', ''), reverse=True):
        url = eval['url']
        if url not in seen_urls:
            seen_urls[url] = eval
    
    unique_evals = list(seen_urls.values())
    
    if not unique_evals:
        print("âš ï¸ æ²¡æœ‰è¯„æµ‹æ•°æ®")
        return
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_sites = len(unique_evals)
    scores = [e['result']['result']['score'] for e in unique_evals]
    avg_score = sum(scores) / len(scores)
    
    # åˆ†çº§ç»Ÿè®¡
    grade_counts = {'S': 0, 'A': 0, 'B': 0, 'C': 0}
    for e in unique_evals:
        grade = e['result']['result']['grade']
        grade_letter = grade[6] if len(grade) > 6 else 'C'
        if grade_letter in grade_counts:
            grade_counts[grade_letter] += 1
    
    # ç”ŸæˆæŠ¥å‘Š
    lines = []
    lines.append("## ğŸ“Š è¯„æµ‹ç»Ÿè®¡\n")
    lines.append(f"- **æ€»è®¡è¯„æµ‹ç½‘ç«™**: {total_sites} ä¸ª")
    lines.append(f"- **å¹³å‡åˆ†æ•°**: {avg_score:.1f}/100")
    lines.append(f"- **æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
    
    lines.append("### ç­‰çº§åˆ†å¸ƒ\n")
    for grade in ['S', 'A', 'B', 'C']:
        count = grade_counts.get(grade, 0)
        bar = 'â–ˆ' * count
        lines.append(f"- **{grade}**: {count} {bar}")
    lines.append("")
    
    lines.append("### æœ€æ–°è¯„æµ‹ç»“æœ\n")
    lines.append("| ç½‘ç«™ | åˆ†æ•° | ç­‰çº§ | è¯„æµ‹æ—¶é—´ |")
    lines.append("|------|------|------|----------|")
    
    for eval in unique_evals[:15]:
        url = eval["url"].replace("https://", "").replace("http://", "")[:28]
        result = eval["result"]["result"]
        score = result["score"]
        grade = result["grade"][6] if len(result["grade"]) > 6 else "?"
        time = eval["timestamp"][:16].replace("T", " ") if 'T' in eval["timestamp"] else eval["timestamp"][:16]
        lines.append(f"| {url} | {score} | {grade} | {time} |")
    
    lines.append("")
    
    readme_section = "\n".join(lines)
    
    # æ›´æ–° README
    readme_path = PROJECT_DIR / "README.md"
    with open(readme_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    marker_start = "<!-- EVALUATION_RESULTS_START -->"
    marker_end = "<!-- EVALUATION_RESULTS_END -->"
    
    if marker_start in content and marker_end in content:
        parts = content.split(marker_start)
        new_content = parts[0] + marker_start + "\n\n" + readme_section + marker_end + content.split(marker_end)[1]
    else:
        new_content = content + "\n\n" + marker_start + "\n\n" + readme_section + marker_end + "\n"
    
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print("âœ… README å·²æ›´æ–°")


def git_push():
    """æ¨é€åˆ° GitHub"""
    try:
        os.chdir(PROJECT_DIR)
        
        subprocess.run(["git", "config", "user.email", "auto@openaix.org"], check=False, capture_output=True)
        subprocess.run(["git", "config", "user.name", "OpenAIX Bot"], check=False, capture_output=True)
        
        subprocess.run(["git", "add", "-A"], check=False, capture_output=True)
        
        result = subprocess.run(["git", "diff", "--cached", "--quiet"], capture_output=True)
        if result.returncode == 0:
            print("â„¹ï¸ æ— æ›´æ”¹éœ€æäº¤")
            return
        
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        count = len(list(DATA_DIR.rglob('*.json'))) - 1  # æ’é™¤ evaluated_sites.json
        
        subprocess.run([
            "git", "commit", "-m", 
            f"ğŸ“Š Auto eval: {count} sites - {timestamp}"
        ], check=False, capture_output=True)
        
        push_result = subprocess.run(["git", "push"], capture_output=True, text=True)
        if push_result.returncode == 0:
            print("âœ… å·²æ¨é€åˆ° GitHub")
        else:
            print(f"âš ï¸ æ¨é€é—®é¢˜: {push_result.stderr[:200]}")
            
    except Exception as e:
        print(f"âŒ Git é”™è¯¯: {e}")


def main():
    print("="*60)
    print("ğŸ¤– OpenAIX è‡ªåŠ¨è¯„æµ‹ç³»ç»Ÿ v2.0")
    print("="*60)
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“¦ æ¯å°æ—¶è¯„æµ‹: {BATCH_SIZE} ä¸ªç½‘ç«™")
    print()
    
    # å·²è¯„æµ‹ç½‘ç«™
    evaluated = get_evaluated_sites()
    print(f"ğŸ“Š å·²è¯„æµ‹ç½‘ç«™: {len(evaluated)} ä¸ª")
    
    # é€‰æ‹©ç½‘ç«™
    urls = select_websites(BATCH_SIZE)
    print(f"ğŸ¯ æœ¬æ¬¡è¯„æµ‹: {len(urls)} ä¸ªç½‘ç«™")
    for url in urls:
        print(f"   â€¢ {url}")
    print()
    
    # åˆ›å»ºä»Šæ—¥ç›®å½•
    today = datetime.now().strftime('%Y%m%d')
    today_dir = DATA_DIR / today
    today_dir.mkdir(exist_ok=True)
    
    # è¯„æµ‹
    results = []
    new_evaluated = set()
    
    for url in urls:
        result = evaluate_website(url, today_dir)
        if result:
            results.append(result)
            new_evaluated.add(url)
    
    # æ›´æ–°å·²è¯„æµ‹åˆ—è¡¨
    evaluated.update(new_evaluated)
    save_evaluated_sites(evaluated)
    
    print(f"\nğŸ“ˆ æœ¬æ¬¡æˆåŠŸ: {len(results)}/{len(urls)}")
    
    if results:
        print("\nğŸ“ æ›´æ–° README...")
        update_readme(results)
        
        print("\nğŸš€ æ¨é€åˆ° GitHub...")
        git_push()
        
        print("\n" + "="*60)
        print("âœ… å®Œæˆ!")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("âš ï¸ å…¨éƒ¨å¤±è´¥")
        print("="*60)
        sys.exit(1)


if __name__ == '__main__':
    main()
